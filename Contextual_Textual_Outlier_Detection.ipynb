{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Contextual Outlier Detection and Removal in Synthetic Textual Data using Local Outlier Detection(LOF)"
      ],
      "metadata": {
        "id": "7l9BvgkwNsh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf7obd2eN-SC",
        "outputId": "000a520d-68b6-4caf-98cb-44e6c0219f25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (26.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker"
      ],
      "metadata": {
        "id": "dyRqiC5MOD4C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake= Faker()"
      ],
      "metadata": {
        "id": "_O_gRyxkOFyl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "fake_sentences = [fake.sentence() for _ in range(50)]\n",
        "outlier_count = int(0.4 * len(fake_sentences)) #adding 40% outliers in synthetic data\n",
        "outlier_indices = random.sample(range(len(fake_sentences)), outlier_count)\n",
        "outlier_sentences = [fake.sentence() for _ in range(outlier_count)]\n",
        "for idx, outlier_idx in enumerate(outlier_indices):\n",
        "    fake_sentences[outlier_idx] = outlier_sentences[idx]\n",
        "fake_text_with_outliers = '\\n'.join(fake_sentences)\n",
        "sentences = fake_text_with_outliers.split('\\n')\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "pjfMzlTrOJl0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fake_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGotq9wpOKNd",
        "outputId": "33c27e51-7a43-4300-b644-b084d810a9d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Discover where nice discuss.', 'Attack office any.', 'Entire pattern kitchen turn play before.', 'Move keep strong.', 'Give during owner system vote.', 'New certain lot forget.', 'A again everything into include would adult least.', 'Person hot policy.', 'Box reality address.', 'Day view worry fly able from seek.', 'You fine phone difference against.', 'Research dark side relationship century action affect.', 'Chance left citizen dinner attention many quality simple.', 'Participant challenge fear against huge.', 'Take bill weight system would picture.', 'Interest certainly what perform.', 'Town popular attention note.', 'Daughter subject discover hope computer there do.', 'Close field guess.', 'Century street recognize idea focus key structure top.', 'Various often particularly.', 'Fish American order meet.', 'Rule land shake executive from hard star.', 'Artist house according among window list.', 'Responsibility dinner according knowledge believe prove.', 'Fear assume pull decision policy beyond.', 'Amount five social with next medical piece certainly.', 'Town role receive find hundred.', 'Drive picture test trip threat son.', 'Down performance late around.', 'Final hospital now population.', 'Shake cultural outside almost.', 'Smile cut six might individual research.', 'In society listen system garden answer call.', 'Bag choose collection fish many foreign.', 'Enjoy husband hold.', 'Use fly husband attack.', 'Should floor wrong list front phone woman.', 'Fast resource investment perhaps game.', 'Team into suggest charge cultural contain sign to.', 'Interview these pressure executive send for protect good.', 'According along land another to.', 'Clearly rather work really.', 'Name final onto stage population.', 'Or arrive guess administration tax.', 'Here current carry it somebody where without.', 'Note fast between.', 'Protect tough glass prevent billion.', 'Couple answer water about join.', 'Music from social like but movie relate.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(sentences)\n",
        "n_samples = X.shape[0]\n",
        "n_neighbors = min(20, n_samples - 1) if n_samples > 1 else 1\n",
        "print(\"Text Block:\")\n",
        "print(fake_text_with_outliers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU18r-OsONqw",
        "outputId": "27591c40-32da-47c0-c440-e54729443410"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Block:\n",
            "Discover where nice discuss.\n",
            "Attack office any.\n",
            "Entire pattern kitchen turn play before.\n",
            "Move keep strong.\n",
            "Give during owner system vote.\n",
            "New certain lot forget.\n",
            "A again everything into include would adult least.\n",
            "Person hot policy.\n",
            "Box reality address.\n",
            "Day view worry fly able from seek.\n",
            "You fine phone difference against.\n",
            "Research dark side relationship century action affect.\n",
            "Chance left citizen dinner attention many quality simple.\n",
            "Participant challenge fear against huge.\n",
            "Take bill weight system would picture.\n",
            "Interest certainly what perform.\n",
            "Town popular attention note.\n",
            "Daughter subject discover hope computer there do.\n",
            "Close field guess.\n",
            "Century street recognize idea focus key structure top.\n",
            "Various often particularly.\n",
            "Fish American order meet.\n",
            "Rule land shake executive from hard star.\n",
            "Artist house according among window list.\n",
            "Responsibility dinner according knowledge believe prove.\n",
            "Fear assume pull decision policy beyond.\n",
            "Amount five social with next medical piece certainly.\n",
            "Town role receive find hundred.\n",
            "Drive picture test trip threat son.\n",
            "Down performance late around.\n",
            "Final hospital now population.\n",
            "Shake cultural outside almost.\n",
            "Smile cut six might individual research.\n",
            "In society listen system garden answer call.\n",
            "Bag choose collection fish many foreign.\n",
            "Enjoy husband hold.\n",
            "Use fly husband attack.\n",
            "Should floor wrong list front phone woman.\n",
            "Fast resource investment perhaps game.\n",
            "Team into suggest charge cultural contain sign to.\n",
            "Interview these pressure executive send for protect good.\n",
            "According along land another to.\n",
            "Clearly rather work really.\n",
            "Name final onto stage population.\n",
            "Or arrive guess administration tax.\n",
            "Here current carry it somebody where without.\n",
            "Note fast between.\n",
            "Protect tough glass prevent billion.\n",
            "Couple answer water about join.\n",
            "Music from social like but movie relate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "import numpy as np\n",
        "lof = LocalOutlierFactor(n_neighbors=n_neighbors)\n",
        "outlier_scores = lof.fit_predict(X.toarray())\n",
        "outlier_percentage = (np.sum(outlier_scores == -1) / len(outlier_scores)) * 100\n",
        "print(f\"\\nPercentage of outliers detected by LOF: {outlier_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T207WpEPOVJa",
        "outputId": "04510929-aa58-4307-e433-a37657dee2c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of outliers detected by LOF: 38.00%\n"
          ]
        }
      ]
    }
  ]
}